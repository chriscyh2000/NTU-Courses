{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b09901073/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import transformers\n",
    "import json, pickle\n",
    "from models import *\n",
    "from tqdm import tqdm\n",
    "from utils import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserCourseDataset(Dataset):\n",
    "    def __init__(self, users, user_embeds, total_courses=92):\n",
    "        self.users = users\n",
    "        self.user_embeds = [torch.from_numpy(user_embed) for user_embed in user_embeds]\n",
    "        self.total_courses = total_courses\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels = torch.zeros(self.total_courses)\n",
    "        labels = labels.scatter_(0, torch.tensor(self.users[idx][\"subgroups\"]), 1)\n",
    "        user_embed = self.user_embeds[idx]\n",
    "        return user_embed, labels\n",
    "\n",
    "def collate_fn(batch):\n",
    "    ### pad the user_embeds to the same length\n",
    "    # print(batch[0][0].shape)\n",
    "    max_len = max([item[0].shape[0] for item in batch])\n",
    "    embed_dim = batch[0][0].shape[1]\n",
    "    user_embeds = torch.stack([torch.cat([item[0], torch.zeros(max_len - item[0].shape[0], embed_dim)], dim=0) for item in batch])\n",
    "    labels = torch.stack([item[1] for item in batch])\n",
    "    return user_embeds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embed_path = \"processed_datas/combined_train_users_embeddings.pkl\"\n",
    "user_path = \"processed_datas/combined_train_users.json\"\n",
    "\n",
    "with open(user_path, \"r\") as f:\n",
    "    users = json.load(f)\n",
    "\n",
    "with open(user_embed_path, \"rb\") as f:\n",
    "    user_embeds = pickle.load(f)\n",
    "\n",
    "\n",
    "trainset = UserCourseDataset(users, user_embeds)\n",
    "\n",
    "user_embed_path = \"processed_datas/combined_valid_embeddings.pkl\"\n",
    "user_path = \"processed_datas/combined_valid.json\"\n",
    "\n",
    "with open(user_path, \"r\") as f:\n",
    "    users = json.load(f)\n",
    "\n",
    "with open(user_embed_path, \"rb\") as f:\n",
    "    user_embeds = pickle.load(f)\n",
    "\n",
    "\n",
    "validset = UserCourseDataset(users, user_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\n",
    "    return nn.BCEWithLogitsLoss(pos_weight=3.0 * torch.ones(92))(logits, labels)\n",
    "\n",
    "\n",
    "def eval_metric(logits, labels, k=50):\n",
    "    preds = torch.argsort(logits, dim=-1, descending=True)[:, :k]\n",
    "    labels = torch.where(labels == 1)\n",
    "    labels = [labels[1][labels[0] == i].tolist() for i in range(preds.shape[0])]\n",
    "    return mapk(labels, preds, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(validset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "model = ValModelv0(nhead=8, num_tokens=92, in_size=512).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5, verbose=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0, loss: 0.2633805887371573, rec: 8.930641926988663, topk: 0.4222722120821395\n",
      "valid epoch: 0, loss: 0.23291627853945063, rec: 8.337474930417407, topk: 0.30907754711022256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.26381993047138813, rec: 8.936663070846254, topk: 0.41866477000184\n",
      "valid epoch: 1, loss: 0.2328363212828453, rec: 8.489458158776001, topk: 0.31385617430533796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2, loss: 0.2636929632877371, rec: 8.936317476028417, topk: 0.41920584622811485\n",
      "valid epoch: 2, loss: 0.23262736627033778, rec: 8.409374054971632, topk: 0.3093070320736781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3, loss: 0.2633291048341469, rec: 8.930079070654667, topk: 0.42011693288051305\n",
      "valid epoch: 3, loss: 0.23129004080380713, rec: 8.25495588517451, topk: 0.3127525230295533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4, loss: 0.2631046356574443, rec: 8.928742397259311, topk: 0.4205925150371123\n",
      "valid epoch: 4, loss: 0.2315530657850124, rec: 7.733442015700287, topk: 0.30835361134609357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5, loss: 0.26282695400312617, rec: 8.925251087531983, topk: 0.42114177957065035\n",
      "valid epoch: 5, loss: 0.23204701618997606, rec: 7.863789743119543, topk: 0.30481688457283757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6, loss: 0.2626246217424753, rec: 8.915832558863292, topk: 0.4219026705450887\n",
      "valid epoch: 6, loss: 0.23269697974671374, rec: 8.07107574075133, topk: 0.30778532907504613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7, loss: 0.26228795164271224, rec: 8.915373454581752, topk: 0.4226960766154043\n",
      "valid epoch: 7, loss: 0.2324818234358515, rec: 8.357914171376072, topk: 0.3103036070049259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:54<00:00, 34.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8, loss: 0.2621214967969272, rec: 8.912709308679435, topk: 0.42342064270222635\n",
      "valid epoch: 8, loss: 0.23330078757071232, rec: 7.872859979723836, topk: 0.3029053816513018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:53<00:00, 34.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9, loss: 0.2617958554560064, rec: 8.904940643474005, topk: 0.42343177414947064\n",
      "valid epoch: 9, loss: 0.2313914662534064, rec: 7.880815977578635, topk: 0.31128877210448863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 887/1867 [00:25<00:28, 34.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     17\u001b[0m     recs\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39msigmoid(logits)\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem())\n\u001b[0;32m---> 18\u001b[0m     topks\u001b[39m.\u001b[39mappend(eval_metric(logits, labels))\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, rec: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, topk: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch, np\u001b[39m.\u001b[39mmean(losses), np\u001b[39m.\u001b[39mmean(recs), np\u001b[39m.\u001b[39mmean(topks)))\n\u001b[1;32m     21\u001b[0m losses \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36meval_metric\u001b[0;34m(logits, labels, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(labels \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m labels \u001b[39m=\u001b[39m [labels[\u001b[39m1\u001b[39m][labels[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m i]\u001b[39m.\u001b[39mtolist() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(preds\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])]\n\u001b[0;32m----> 9\u001b[0m \u001b[39mreturn\u001b[39;00m mapk(labels, preds, \u001b[39m50\u001b[39;49m)\n",
      "File \u001b[0;32m~/adlfinal/adl-final/utils.py:91\u001b[0m, in \u001b[0;36mmapk\u001b[0;34m(actual, predicted, k)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmapk\u001b[39m(actual, predicted, k\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    Computes the mean average precision at k.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean([apk(a,p,k) \u001b[39mfor\u001b[39;00m a,p \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(actual, predicted)])\n",
      "File \u001b[0;32m~/adlfinal/adl-final/utils.py:91\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmapk\u001b[39m(actual, predicted, k\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    Computes the mean average precision at k.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean([apk(a,p,k) \u001b[39mfor\u001b[39;00m a,p \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(actual, predicted)])\n",
      "File \u001b[0;32m~/adlfinal/adl-final/utils.py:58\u001b[0m, in \u001b[0;36mapk\u001b[0;34m(actual, predicted, k)\u001b[0m\n\u001b[1;32m     55\u001b[0m num_hits \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m i,p \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(predicted):\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mif\u001b[39;00m p \u001b[39min\u001b[39;49;00m actual \u001b[39mand\u001b[39;00m p \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m predicted[:i]:\n\u001b[1;32m     59\u001b[0m         num_hits \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m     60\u001b[0m         score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m num_hits \u001b[39m/\u001b[39m (i\u001b[39m+\u001b[39m\u001b[39m1.0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "topk_scores = [0 for _ in range(k)]\n",
    "\n",
    "\n",
    "for epoch in range(60):\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    for user_embeds, labels in tqdm(train_loader):\n",
    "        user_embeds = user_embeds.cuda()\n",
    "        logits = model(user_embeds).cpu()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        recs.append(torch.sigmoid(logits).sum(dim=-1).mean().item())\n",
    "        topks.append(eval_metric(logits, labels))\n",
    "    print(\"train epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for user_embeds, labels in valid_loader:\n",
    "            user_embeds = user_embeds.cuda()\n",
    "            logits = model(user_embeds).cpu()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "            recs.append(torch.sigmoid(logits).sum(dim=-1).mean().item())\n",
    "            topks.append(eval_metric(logits, labels))\n",
    "    print(\"valid epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "    if np.mean(topks) > min(topk_scores):\n",
    "        i = topk_scores.index(min(topk_scores))\n",
    "        topk_scores[i] = np.mean(topks)\n",
    "        torch.save(model.state_dict(), \"ckpts/val_modelv0_{}.pth\".format(i))\n",
    "    model.train()\n",
    "    # lr_scheduler.step(np.mean(topks))\n",
    "\n",
    "print(topk_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3180500737698619, 0.3131914555527006, 0.31731365500919856, 0.31211073845310017, 0.31571356170372056, 0.3167765206503458, 0.31362011125222683, 0.31175490433947184, 0.31295463092443715, 0.31206028410984915]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(topk_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "825ef558ec91ccb369c5ade66cb9ed2dc49eb7a1baf3f301fee22ad84418e33e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
