{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b09901073/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import transformers\n",
    "import json, pickle\n",
    "from models import *\n",
    "from tqdm import tqdm\n",
    "from utils import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserCourseDataset(Dataset):\n",
    "    def __init__(self, users, user_embeds, total_courses=732):\n",
    "        self.users = users\n",
    "        self.user_embeds = [torch.from_numpy(user_embed) for user_embed in user_embeds]\n",
    "        self.total_courses = total_courses\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels = torch.zeros(self.total_courses)\n",
    "        labels = labels.scatter_(0, torch.tensor(self.users[idx][\"labels\"]), 1)\n",
    "        user_embed = self.user_embeds[idx]\n",
    "        return user_embed, labels\n",
    "\n",
    "def collate_fn(batch):\n",
    "    ### pad the user_embeds to the same length\n",
    "    # print(batch[0][0].shape)\n",
    "    max_len = max([item[0].shape[0] for item in batch])\n",
    "    embed_dim = batch[0][0].shape[1]\n",
    "    user_embeds = torch.stack([torch.cat([item[0], torch.zeros(max_len - item[0].shape[0], embed_dim)], dim=0) for item in batch])\n",
    "    labels = torch.stack([item[1] for item in batch])\n",
    "    return user_embeds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embed_path = \"processed_datas/train_users_embeddings.pkl\"\n",
    "user_path = \"processed_datas/train_users.json\"\n",
    "course_embed_path = \"processed_datas/train_courses_embeddings.pkl\"\n",
    "\n",
    "with open(user_path, \"r\") as f:\n",
    "    users = json.load(f)\n",
    "\n",
    "with open(user_embed_path, \"rb\") as f:\n",
    "    user_embeds = pickle.load(f)\n",
    "\n",
    "#user_embeds = [user_embed.reshape(1, -1).astype(np.float32) for user_embed in user_embeds]\n",
    "\n",
    "trainset = UserCourseDataset(users, user_embeds)\n",
    "\n",
    "user_embed_path = \"processed_datas/val_unseen_embeddings.pkl\"\n",
    "user_path = \"processed_datas/val_unseen.json\"\n",
    "\n",
    "with open(user_path, \"r\") as f:\n",
    "    users = json.load(f)\n",
    "\n",
    "with open(user_embed_path, \"rb\") as f:\n",
    "    user_embeds = pickle.load(f)\n",
    "\n",
    "#user_embeds = [user_embed.reshape(1, -1).astype(np.float32) for user_embed in user_embeds]\n",
    "\n",
    "\n",
    "validset = UserCourseDataset(users, user_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b09901073/anaconda3/envs/adl/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/b09901073/anaconda3/envs/adl/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/tmp/ipykernel_2546441/2012190320.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  json.dump(np.array(train_labels_count).astype(np.int).tolist(), open(\"processed_datas/train_labels_count.json\", \"w\"))\n"
     ]
    }
   ],
   "source": [
    "train_labels = [trainset[i][1] for i in range(len(trainset))]\n",
    "train_labels_count = np.sum(train_labels, axis=0)\n",
    "json.dump(np.array(train_labels_count).astype(np.int).tolist(), open(\"processed_datas/train_labels_count.json\", \"w\"))\n",
    "negative_weight = train_labels_count / len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn(logits, labels, rec_num=50, rec_weight=0.001):\n",
    "#     positive_mask = labels.type(torch.bool)\n",
    "#     positive_loss = nn.BCELoss()(logits[positive_mask], labels[positive_mask])\n",
    "#     rec_loss = nn.L1Loss()(logits.sum(dim=-1), rec_num*torch.ones(logits.shape[0]))\n",
    "#     return positive_loss + rec_weight * rec_loss\n",
    "\n",
    "def loss_fn(logits, labels):\n",
    "    return nn.BCEWithLogitsLoss(pos_weight=200 * torch.ones(732))(logits, labels)\n",
    "\n",
    "\n",
    "def eval_metric(logits, labels, k=50):\n",
    "    preds = torch.argsort(logits, dim=-1, descending=True)[:, :k]\n",
    "    labels = torch.where(labels == 1)\n",
    "    labels = [labels[1][labels[0] == i].tolist() for i in range(preds.shape[0])]\n",
    "    return mapk(labels, preds, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(validset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "model = ValModelv1(nhead=8).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [01:12<00:00, 25.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0, loss: 0.4033388276916171, rec: 330.6822677064721, topk: 0.030925384256908207\n",
      "valid epoch: 0, loss: 0.32791201246308754, rec: 275.1023646763393, topk: 0.029817128165930153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [01:11<00:00, 26.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.37953317810267, rec: 296.19407363670933, topk: 0.04562856524530621\n",
      "valid epoch: 1, loss: 0.31842441586675224, rec: 256.8728516966432, topk: 0.03935474293571417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [01:11<00:00, 26.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2, loss: 0.37428991996992955, rec: 289.38067498638725, topk: 0.04884069129999926\n",
      "valid epoch: 2, loss: 0.32483375506414164, rec: 293.71946909139444, topk: 0.03609003507125146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 112/1867 [00:04<01:08, 25.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, labels)\n\u001b[1;32m     11\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 12\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     13\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.8/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.8/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.8/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.8/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.8/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_topk = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    for user_embeds, labels in tqdm(train_loader):\n",
    "        user_embeds = user_embeds.cuda()\n",
    "        logits = model(user_embeds).cpu()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        recs.append(torch.sigmoid(logits).sum(dim=-1).mean().item())\n",
    "        topks.append(eval_metric(logits, labels))\n",
    "    print(\"train epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for user_embeds, labels in valid_loader:\n",
    "            user_embeds = user_embeds.cuda()\n",
    "            logits = model(user_embeds).cpu()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "            recs.append(torch.sigmoid(logits).sum(dim=-1).mean().item())\n",
    "            topks.append(eval_metric(logits, labels))\n",
    "    print(\"valid epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "    if np.mean(topks) > best_topk:\n",
    "        best_topk = np.mean(topks)\n",
    "        torch.save(model.state_dict(), \"val_modelv1.pth\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(validset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "model = ValModelv0(nhead=8, in_size=512, dropout=0.1, hidden_size=256).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:58<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0, loss: 0.6755380030934927, rec: 164.993839813543, topk: 0.16413441316519223\n",
      "valid epoch: 0, loss: 1.276698078264247, rec: 128.60163414085304, topk: 0.0766969926483974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.6028936509148731, rec: 142.6512653532677, topk: 0.19043870196842944\n",
      "valid epoch: 1, loss: 1.4861792299773666, rec: 109.47398064162705, topk: 0.0821112780426354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2, loss: 0.5780242734818645, rec: 135.60534616888177, topk: 0.20315493772580492\n",
      "valid epoch: 2, loss: 1.6541208261316949, rec: 111.33684789217435, topk: 0.08848893809739125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3, loss: 0.5644772513447819, rec: 131.93885116291096, topk: 0.20936272898262343\n",
      "valid epoch: 3, loss: 1.6262995424670177, rec: 117.38719694955009, topk: 0.10342494296722145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4, loss: 0.553471740644503, rec: 129.17947395050916, topk: 0.2140272677124576\n",
      "valid epoch: 4, loss: 1.765723467364416, rec: 113.61467977670523, topk: 0.10306487704780257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5, loss: 0.5453932853580223, rec: 126.91718217454368, topk: 0.2155389231163919\n",
      "valid epoch: 5, loss: 2.0340358441347606, rec: 100.11638869820061, topk: 0.10479374189497277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6, loss: 0.5386738210166273, rec: 125.252509147264, topk: 0.2185500580371749\n",
      "valid epoch: 6, loss: 2.078260803615654, rec: 109.88975007193429, topk: 0.10196218173809811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7, loss: 0.5324629967584288, rec: 123.85094782089128, topk: 0.21942103011115496\n",
      "valid epoch: 7, loss: 2.1953829310752533, rec: 102.73514885954805, topk: 0.10570963321332695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8, loss: 0.5263505103470619, rec: 122.0814146420888, topk: 0.22165105730413381\n",
      "valid epoch: 8, loss: 2.1891650338094313, rec: 107.83895607833024, topk: 0.10067057316625545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9, loss: 0.5196851408762541, rec: 120.6750876371019, topk: 0.2233213276142079\n",
      "valid epoch: 9, loss: 2.289363757594601, rec: 108.31105007968107, topk: 0.10547693398331065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 10, loss: 0.5137105180448431, rec: 119.16264700008448, topk: 0.22343351281158205\n",
      "valid epoch: 10, loss: 2.3145128328066606, rec: 102.71819395547385, topk: 0.10185518094841636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 11, loss: 0.5074013094086026, rec: 117.7758975322705, topk: 0.22345917686078032\n",
      "valid epoch: 11, loss: 2.3528976430604747, rec: 100.64430827884884, topk: 0.10768030617549103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 12, loss: 0.5017709277598182, rec: 116.3920607073906, topk: 0.2244693527230246\n",
      "valid epoch: 12, loss: 2.457051850609727, rec: 103.87707167405348, topk: 0.09942613983843857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 13, loss: 0.49482603641710754, rec: 114.86037361296218, topk: 0.22490919503365447\n",
      "valid epoch: 13, loss: 2.3146764226667176, rec: 103.85982790098086, topk: 0.10316227361871633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 14, loss: 0.4881361583751603, rec: 113.27570393280863, topk: 0.224100372639881\n",
      "valid epoch: 14, loss: 2.425076356300941, rec: 100.47506741115025, topk: 0.10725924485228637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 15, loss: 0.4810872413317788, rec: 111.62397964305909, topk: 0.2239141198846739\n",
      "valid epoch: 15, loss: 2.3180025349279028, rec: 109.94460451733936, topk: 0.10436176280578621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 16, loss: 0.4746067031188387, rec: 110.17828733651601, topk: 0.22391975325651284\n",
      "valid epoch: 16, loss: 2.3501097013007155, rec: 116.21787513481392, topk: 0.10319883995855918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 17, loss: 0.466961472939219, rec: 108.47853752835013, topk: 0.22382289260202815\n",
      "valid epoch: 17, loss: 2.4167692278112685, rec: 105.33131004165817, topk: 0.10393228268873539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 18, loss: 0.45975393289924626, rec: 106.57046172065918, topk: 0.22466804434080506\n",
      "valid epoch: 18, loss: 2.4877915398760155, rec: 108.41508607549981, topk: 0.1041999714013897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 19, loss: 0.4522537743911171, rec: 104.9320339249875, topk: 0.22362265995895375\n",
      "valid epoch: 19, loss: 2.4721046895771237, rec: 103.4971070761209, topk: 0.09892031262096332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 20, loss: 0.4453026420079136, rec: 103.31549431055576, topk: 0.22469868651172595\n",
      "valid epoch: 20, loss: 2.5119570591947533, rec: 106.74534776708582, topk: 0.09549705882607491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:56<00:00, 32.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 21, loss: 0.43787223290618116, rec: 101.49100778392757, topk: 0.2221233203508489\n",
      "valid epoch: 21, loss: 2.7716301681248696, rec: 95.61096998361441, topk: 0.10009232126867175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 22, loss: 0.43063990577823924, rec: 99.82187300744897, topk: 0.22149303699030762\n",
      "valid epoch: 22, loss: 2.7841177576190823, rec: 96.85222386789846, topk: 0.09579228638442124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:58<00:00, 31.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 23, loss: 0.42368293239525057, rec: 98.01173404556708, topk: 0.22129344618203087\n",
      "valid epoch: 23, loss: 2.8004819554286997, rec: 99.9300924028669, topk: 0.09743344879256494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:58<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 24, loss: 0.41660215413117063, rec: 96.43606515893593, topk: 0.22013845291885106\n",
      "valid epoch: 24, loss: 2.777795436618092, rec: 95.15139602828812, topk: 0.09482387284880492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 25, loss: 0.41021585777346053, rec: 94.74756771061085, topk: 0.21873659694479033\n",
      "valid epoch: 25, loss: 2.820357728790451, rec: 92.9377202463674, topk: 0.09331308906476606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:58<00:00, 32.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 26, loss: 0.40430883371261717, rec: 93.26246732968217, topk: 0.21790205326191153\n",
      "valid epoch: 26, loss: 2.795144809471382, rec: 97.58856435922476, topk: 0.08872841130845835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 27, loss: 0.3976326773175596, rec: 91.75496312750809, topk: 0.21942767735660557\n",
      "valid epoch: 27, loss: 3.0455690036108205, rec: 91.69885863838616, topk: 0.07947509644261551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:58<00:00, 31.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 28, loss: 0.39198306962712026, rec: 90.35867240918022, topk: 0.2168464699167425\n",
      "valid epoch: 28, loss: 2.927065229022896, rec: 96.01369193360046, topk: 0.08294846985021492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [00:57<00:00, 32.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 29, loss: 0.38577445560939566, rec: 88.72915635520147, topk: 0.21695910393882917\n",
      "valid epoch: 29, loss: 2.9405050595383067, rec: 97.51323400224958, topk: 0.08022687792457599\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    for user_embeds, labels in tqdm(train_loader):\n",
    "        user_embeds = user_embeds.cuda()\n",
    "        logits = model(user_embeds).cpu()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        recs.append(torch.sigmoid(logits).sum(dim=-1).mean().item())\n",
    "        topks.append(eval_metric(logits, labels))\n",
    "    print(\"train epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for user_embeds, labels in valid_loader:\n",
    "            user_embeds = user_embeds.cuda()\n",
    "            logits = model(user_embeds).cpu()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "            recs.append(torch.sigmoid(logits).sum(dim=-1).mean().item())\n",
    "            topks.append(eval_metric(logits, labels))\n",
    "    print(\"valid epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "    if np.mean(topks) > best_score:\n",
    "        best_score = np.mean(topks)\n",
    "        torch.save(model.state_dict(), \"val_modelv0.pth\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=512, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(validset, batch_size=512, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = ValModelv2().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "def loss_fn(logits, labels, margin=0.1, negative_weight=0.3):\n",
    "    positive_mask = labels.type(torch.bool)\n",
    "    positive_loss = torch.clamp(1.0 - logits[positive_mask]-margin, min=0).mean()\n",
    "    negative_loss = logits[~positive_mask].mean()\n",
    "    return positive_loss + negative_weight * negative_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:44<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0, loss: 0.766678167714013, rec: 4.449799065151785, topk: 0.14409379729010702\n",
      "valid epoch: 0, loss: 0.8116465029509171, rec: 2.4035574975221055, topk: 0.07683248175912097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.7304033927428417, rec: 2.534630176348564, topk: 0.1774733906402815\n",
      "valid epoch: 1, loss: 0.7995522151822629, rec: 1.314250567685003, topk: 0.08595529080869732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2, loss: 0.7056796688299912, rec: 0.48750328705208296, topk: 0.18878886096510775\n",
      "valid epoch: 2, loss: 0.7931088001831718, rec: -0.5277866954388826, topk: 0.08964996539978001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3, loss: 0.6828133861223856, rec: -1.8289444759870186, topk: 0.19182157897608665\n",
      "valid epoch: 3, loss: 0.7855333530384562, rec: -2.6289356273153555, topk: 0.08898914107559416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4, loss: 0.6599316439058027, rec: -4.2461754277221155, topk: 0.19353123097044944\n",
      "valid epoch: 4, loss: 0.7791087083194567, rec: -5.1508641450301464, topk: 0.0884494247672093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5, loss: 0.6371049442861834, rec: -6.818087638952793, topk: 0.19334731663582247\n",
      "valid epoch: 5, loss: 0.7741616549699203, rec: -7.222916872605033, topk: 0.08584312275092106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6, loss: 0.6141945052350688, rec: -9.374691555642674, topk: 0.19287406066290558\n",
      "valid epoch: 6, loss: 0.7652964980705924, rec: -9.348411145417586, topk: 0.09144101392728285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7, loss: 0.5917456557608058, rec: -11.967124009743715, topk: 0.1919395911850983\n",
      "valid epoch: 7, loss: 0.7585260842157446, rec: -12.235948977263078, topk: 0.08691540319209114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8, loss: 0.569560245061532, rec: -14.517706903636965, topk: 0.19170585932846912\n",
      "valid epoch: 8, loss: 0.754508508288342, rec: -14.345203524050506, topk: 0.08492243145754241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:45<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9, loss: 0.5479295992443705, rec: -17.033421760950333, topk: 0.1903384165568237\n",
      "valid epoch: 9, loss: 0.7471263201340385, rec: -16.769900695137355, topk: 0.08650586522202565\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    for user_embeds, labels in tqdm(train_loader):\n",
    "        user_embeds = user_embeds.cuda()\n",
    "        logits = model(user_embeds).cpu()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        recs.append(logits.sum(dim=-1).mean().item())\n",
    "        topks.append(eval_metric(logits, labels))\n",
    "    print(\"train epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for user_embeds, labels in valid_loader:\n",
    "            user_embeds = user_embeds.cuda()\n",
    "            logits = model(user_embeds).cpu()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "            recs.append(logits.sum(dim=-1).mean().item())\n",
    "            topks.append(eval_metric(logits, labels))\n",
    "    print(\"valid epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b09901073/adlfinal/adl-final/utils.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  return torch.tensor(dataset)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(validset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = ValModelv3().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "def loss_fn(logits, labels, margin=0.1, negative_weight=0.3):\n",
    "    positive_mask = labels.type(torch.bool)\n",
    "    positive_loss = torch.clamp(1.0 - logits[positive_mask]-margin, min=0).mean()\n",
    "    negative_loss = logits[~positive_mask].mean()\n",
    "    return positive_loss + negative_weight * negative_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [03:11<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0, loss: 0.203832466253062, rec: 173.9995898638553, topk: 0.015023128256834932\n",
      "valid epoch: 0, loss: 0.5313135508325074, rec: 88.25882869762378, topk: 0.01273372787846611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1867/1867 [03:10<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.19324947941906642, rec: 102.03775221789401, topk: 0.015853206457859068\n",
      "valid epoch: 1, loss: 0.8500865481712006, rec: -21.5492885021063, topk: 0.0053002652279394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 93/1867 [00:09<03:01,  9.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m recs \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m topks \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m user_embeds, labels \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m      6\u001b[0m     user_embeds \u001b[39m=\u001b[39m user_embeds\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      7\u001b[0m     logits \u001b[39m=\u001b[39m model(user_embeds)\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     19\u001b[0m max_len \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m([item[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m     20\u001b[0m embed_dim \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m user_embeds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39mcat([item[\u001b[39m0\u001b[39m], torch\u001b[39m.\u001b[39mzeros(max_len \u001b[39m-\u001b[39m item[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], embed_dim)], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m     22\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([item[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m user_embeds, labels\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m max_len \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m([item[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m     20\u001b[0m embed_dim \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m user_embeds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39;49mcat([item[\u001b[39m0\u001b[39;49m], torch\u001b[39m.\u001b[39;49mzeros(max_len \u001b[39m-\u001b[39;49m item[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], embed_dim)], dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m     22\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([item[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m user_embeds, labels\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    for user_embeds, labels in tqdm(train_loader):\n",
    "        user_embeds = user_embeds.cuda()\n",
    "        logits = model(user_embeds).cpu()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        recs.append(logits.sum(dim=-1).mean().item())\n",
    "        topks.append(eval_metric(logits, labels))\n",
    "    print(\"train epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for user_embeds, labels in valid_loader:\n",
    "            user_embeds = user_embeds.cuda()\n",
    "            logits = model(user_embeds).cpu()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "            recs.append(logits.sum(dim=-1).mean().item())\n",
    "            topks.append(eval_metric(logits, labels))\n",
    "    print(\"valid epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=512, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(validset, batch_size=512, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = ValModelv4().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 58/117 [00:32<00:33,  1.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m topks \u001b[39m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m user_embeds, labels \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[0;32m----> 6\u001b[0m     user_embeds \u001b[39m=\u001b[39m user_embeds\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m      7\u001b[0m     logits \u001b[39m=\u001b[39m model(user_embeds)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m      8\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(logits, labels)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    for user_embeds, labels in tqdm(train_loader):\n",
    "        user_embeds = user_embeds.cuda()\n",
    "        logits = model(user_embeds).cpu()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        recs.append(torch.sigmoid(logits).sum(dim=-1).mean().item())\n",
    "        topks.append(eval_metric(logits, labels))\n",
    "    print(\"train epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "\n",
    "    losses = []\n",
    "    recs = []\n",
    "    topks = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for user_embeds, labels in valid_loader:\n",
    "            user_embeds = user_embeds.cuda()\n",
    "            logits = model(user_embeds).cpu()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "            recs.append(torch.sigmoid(logits).sum(dim=-1).mean().item())\n",
    "            topks.append(eval_metric(logits, labels))\n",
    "    print(\"valid epoch: {}, loss: {}, rec: {}, topk: {}\".format(epoch, np.mean(losses), np.mean(recs), np.mean(topks)))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "825ef558ec91ccb369c5ade66cb9ed2dc49eb7a1baf3f301fee22ad84418e33e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
